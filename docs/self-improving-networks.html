<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Self-Improving Networks: The Deep Link Between AI and Markets</title>
    <link rel="icon" href="static/icon.jpg" type="image/jpg" />
    <link rel="stylesheet" href="static/style.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css"
      integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP"
      crossorigin="anonymous"
    />
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"
      crossorigin="anonymous"
    ></script>
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mathtex-script-type.min.js"
      crossorigin="anonymous"
    ></script>
    <meta
      name="description"
      content="There is are a few underlying principles that make AI and Markets self-improving networks."
    />
    <meta name="author" content="Jo√£o Abrantes" />

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Self-Improving Networks: The Deep Link Between AI and Markets" />
    <meta
      name="twitter:description"
      content="There is are a few underlying principles that make AI and Markets self-improving networks."
    />
    <meta
      name="twitter:image"
      content="static/icon.jpg"
    />
    <meta name="twitter:site" content="@joaoabrantis" />
  </head>
  <body>
    <header>
      <button onclick="location.href='index.html'">All Articles</button>
      <button class="theme-toggle" id="theme-toggle" aria-label="switch theme">
        üåô/‚òÄÔ∏è
      </button>
    </header>
    <main>
<article>
    <div class="post-header">
        <h1>Self-Improving Networks</h1>
        
            <p class="subtitle">The Deep Link Between AI and Markets</p>
        
    </div>
    <p><em>Published on 2025-05-15</em></p>
    <p>AI is about self-improving neural networks, and markets are about self-improving networks of traders. Self-improving Networks, of any kind, have a lot in common - they follow the same design principles to get better with experience. They also overlap, most tasks traditionally tackled by AI can be reframed as market design problems (examples on this later) - and AI itself is increasingly trading on markets.</p>
<p>However, these two types of networks are also very different in nature. AI improves with more centralisation: the bigger model, with more data and more compute wins. Whereas markets improve with more decentralisation: the market with more participants, more diversity of ideas and lower barriers to entry wins.</p>
<p>In a decentralised World those who find an important truth, by luck or skill, can feed it to the market, and as the world gains from this new knowledge, so does the individual. This dynamic is at the heart of every story worth telling: <a href="https://en.wikipedia.org/wiki/Hero%27s_journey">the hero‚Äôs journey</a>, where discovery benefits both the seeker and the society.</p>
<p>But in a centralised world, only the AI God knows and does it all. In such a world, what will humans dream about? What stories will they have left to tell?</p>
<p>Hopefully, we will never find out. Hopefully, we start giving more thought on how to create more and better Markets.</p>
<h2 id="the-recipe-for-self-improving-networks">The Recipe for Self-Improving Networks</h2>
<p>To cook self-improving networks, we need three ingredients:</p>
<ol>
<li><strong>Objective:</strong> A metric to optimise (maximise or minimise)</li>
<li><strong>Attribution:</strong> A method to measure the contribution of each node to the metric being optimised</li>
<li><strong>Adjustment:</strong> Increase (or decrease) the influence of each node on the metric according to their positive (or negative) contribution</li>
</ol>
<p>Here are a few examples:</p>
<table>
<thead>
<tr>
<th></th>
<th>Neural Networks</th>
<th>Drivers Network (Uber)</th>
<th>Supply Chain</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Nodes of the Network</strong></td>
<td>Neurons</td>
<td>Drivers</td>
<td>Suppliers</td>
</tr>
<tr>
<td><strong>Objective</strong></td>
<td>Loss function</td>
<td>Service Quality</td>
<td>Profit</td>
</tr>
<tr>
<td><strong>Attribution</strong></td>
<td>Backpropagation</td>
<td>User Ratings &amp; Performance Metrics</td>
<td>Quality Control</td>
</tr>
<tr>
<td><strong>Adjustment</strong></td>
<td>Weight update</td>
<td>Show Good Drivers More Often</td>
<td>Bad Suppliers Get Replaced by Competition</td>
</tr>
</tbody>
</table>
<p>In AI, gradients flow through the network, adjusting the influence of each neuron based on its contribution - just as, in markets, money flows between traders, rewarding merit.</p>
<h2 id="prediction-markets-supervised-learning">Prediction Markets = Supervised Learning</h2>
<p>Prediction markets have been designed to solve the classical Supervised Learning tasks such as classification and regression. The math makes it so that the market price is linked to its estimated probability. Traders can profit by making trades that move the market from an inaccurate estimate to an accurate one. But, once the market estimate is correct, no one can make it "more correct", and so no one will be able to profit anymore.</p>
<p>These markets can handle a variety of tasks: classification ("Who will be the next U.S. president?"), regression ("How many cars will Tesla produce next year?), and even conditional predictions ("if Elon is fired, how many cars will Tesla build next year?"). Conditional markets are especially useful for decision-making, as they predict the effects of actions before they are taken. I won't go much into prediction markets as they are already well covered in other places <a href="https://www.youtube.com/watch?v=4yZKGbq1YmA">[1]</a>, <a href="https://mason.gmu.edu/~rhanson/futarchy2013.pdf">[2]</a> and <a href="https://timroughgarden.org/f16/l/l18.pdf">[3]</a>.</p>
<h2 id="supply-chain-reinforcement-learning">Supply Chain = Reinforcement Learning</h2>
<p>A less widely recognized idea is the deep connection between markets and Reinforcement Learning (RL). RL is the AI paradigm focused on understanding and automating sequential decision-making through interaction with an environment. It is widely regarded as the most general framework for modeling intelligence, as it includes perception, planning, and action under uncertainty. Let's first look at the standard RL problem for a single agent with discrete actions, and then reformulate it as a decentralized supply chain problem.</p>
<p>At time <script type="math/tex">t</script>, an RL agent is in state <script type="math/tex">s_t</script> and chooses an action <script type="math/tex">a_t</script>, leading to a new state <script type="math/tex">s_{t+1}</script> and a reward <script type="math/tex">r_t</script>.</p>
<p>Over time, the agent learns a value function <script type="math/tex">Q(s_t, a_t)</script> that estimates total future rewards from taking action <script type="math/tex">a_t</script> in state <script type="math/tex">s_t</script>. Once that function is learned accurately, it guides the agent to take the best action at each state, which is given by <script type="math/tex">a^* = \arg\max_a{Q(s_t, a_t)}</script>.</p>
<p>Analogously, in a <strong>supply chain</strong>, the process begins with raw materials (initial state <script type="math/tex">s_0</script>). At each stage, multiple suppliers submit bids to purchase the current state of the product (<script type="math/tex">s_t</script>). The highest bidder is selected and applies its transformation (action), resulting in a new state <script type="math/tex">s_{t+1}</script>. This transformed product is then sold to the suppliers in the next stage. The supplier's reward is the value added, measured as the difference between the selling price of <script type="math/tex">s_{t+1}</script> and the purchase cost of <script type="math/tex">s_t</script>. Eventually, the final product is sold to the customer, completing the process.</p>
<p>To maximise profit, each supplier must learn an optimal bidding function <script type="math/tex">B(s_t)</script> that outputs how much to bid for each state <script type="math/tex">s_t</script>. Remarkably, if we use a <a href="https://en.wikipedia.org/wiki/Vickrey_auction">Vickrey auction</a> (highest bidder wins, but only pays the second highest price), the optimal bidding strategy for the supplier performing the transformation <script type="math/tex">a</script> matches the optimal <script type="math/tex">Q(s, a)</script> from RL. Therefore, the auction automatically selects the best action for each state by choosing the supplier with the highest bid; <script type="math/tex">a^* = \arg\max_a{Q(s_t, a_t)}</script>.</p>
<h2 id="centralisation-vs-decentralisation-in-self-improving-networks">Centralisation vs Decentralisation in Self-Improving Networks</h2>
<p>I believe the Supply Chain formulation clearly highlights the commonalities and differences between a centralised and decentralised approach to self-improving networks.</p>
<p>On one hand, in the decentralised approach every supplier needs to learn its own bidding function. This is often redundant and wasteful, as similar learning processes are repeated independently across many suppliers. In contrast, the centralised Q-function enables faster learning by aggregating experiences across all states and actions, exploiting common patterns, and reducing redundant computation.</p>
<p>On the other hand, the centralised approach is static, as it is designed to work with a fixed set of known actions. Whereas, the decentralised approach allows a changing number and variety of suppliers to enter, exit and change through innovation. This extra flexibility makes the decentralised approach incredibly robust and adaptable to evolving environments.</p>
<h2 id="markets-for-generative-ai">Markets for Generative AI</h2>
<p>In the past, RL shined on games like Atari and Chess where the set of actions is known and fixed. In the age of Generative AI, action spaces have become infinite: including endless variations of text, code and function calls. This is the age when markets will shine.</p>
<p>To give a concrete example. Imagine a user posts a request offering &#36;10 for the best response: ‚ÄúPlan a three-day tour of Lisbon‚Äù. This is our initial state (<script type="math/tex">s_0</script>). Multiple models believe that they can add value to this state and submit bids. Certainly, the Trip Advisor model is confident it knows a lot about Lisbon and submits a high bid. However, at this stage, the model that best understands the user's tastes and preferences has the most value to contribute. Turns out, our user keeps a diary in Notion, giving the Notion model extra confidence to submit a high bid and make it win the auction. The next state reads as the additional information:</p>
<div class="highlight"><pre><span></span><code>the user has the following preferences:
- avoid tourist traps, sightseeings or anything mainstream
- prefers to explore activities that locals themselves do
- preference to skill-based or learning activities over passive entertainment (e.g. watching a show)
- favourite skill-based activity is surfing
- favourite learning activity is exploring local industry&#39;s history
</code></pre></div>

<p>The added value is enormous! If other models had also acquired <script type="math/tex">s_0</script>, transformed it, and presented their outputs to the next-stage bidders, those bidders would likely offer higher bids for the Notion model's output. In the second stage, the Trip Advisor model lost confidence, it is too mainstream, locals don't use it. Grok wins this round. It has real time access to the Portuguese discussions and discovers local surf spots, the local shoe factory tours, lists the top local restaurants, and cafes. And so the process continues. Subsequent models in the supply chain might incorporate traffic and transportation forecasts, surf conditions, hotel availability, and more. Eventually, a final-stage model purchases the current state with the sole purpose of presenting the completed tour to the user. The closer this final bid is to the full &#36;10, the more confident the model is that the user will accept its version of the itinerary. The user, or his personal AI, then looks at the top 10 offers (ordered by the value of the last bid), picks their favourite and releases the &#36;10. Earlier suppliers are compensated according to their bids.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>There are many markets to be designed for this age and time. They are not only more appropriate for the current technology but they will also lead to a better future!</p>
<p>P.S. I am aggregating a list of interesting market designs to solve real world problems. If you know of any please send me an email or a DM on twitter. This list will probably lead to more blog posts :)</p>
<h2 id="references">References</h2>
<p>Some pointers to work on decentralised RL with local economic transactions:</p>
<p>[1] <a href="https://proceedings.mlr.press/v119/chang20b.html">Chang, Michael, et al. "Decentralized reinforcement learning: Global decision-making via local economic transactions." International Conference on Machine Learning. PMLR, 2020.
</a></p>
<p>[2] <a href="https://people.idsia.ch/~juergen/bucketbrigade/">Schmidhuber, Jurgen. "A local learning algorithm for dynamic feedforward and recurrent networks." Connection Science 1.4 (1989): 403-412.</a></p>
<p>Some pointers to work on Prediction Markets:</p>
<p>[1] <a href="https://www.youtube.com/watch?v=4yZKGbq1YmA">Introduction to Prediction Markets, Robin Hanson</a></p>
<p>[2] <a href="https://mason.gmu.edu/~rhanson/futarchy2013.pdf">Hanson, Robin. "Shall we vote on values, but bet on beliefs?." Journal of Political Philosophy 21.2 (2013): 151-178.</a></p>
<p>[3] <a href="https://timroughgarden.org/f16/l/l18.pdf">Roughgarden, Tim. Lecture #18: Prediction Markets. CS269I: Incentives in Computer Science, Stanford University, 30 Nov. 2016.</a></p>
</article>
</main>
    <footer>
      Tech Entrepreneur and Researcher into Complex Systems and Multi-Agent
      RL<br /><a href="https://x.com/joaoabrantis">@joaoabrantis on Twitter</a>
    </footer>
    <script>
      (() => {
        const root = document.documentElement;
        const btn = document.getElementById("theme-toggle");
        const store = localStorage;
        const DARK = "dark";
        const LIGHT = "light";

        /* 1 ‚ñ∏ restore saved choice, if any */
        const saved = store.getItem("theme");
        if (saved === DARK || saved === LIGHT) {
          root.setAttribute("data-theme", saved);
        }

        /* helper: is the page currently dark? */
        const isDark = () => {
          const attr = root.getAttribute("data-theme");
          return attr
            ? attr === DARK
            : window.matchMedia("(prefers-color-scheme: dark)").matches;
        };

        /* 2 ‚ñ∏ flip on click */
        btn?.addEventListener("click", () => {
          const next = isDark() ? LIGHT : DARK;
          root.setAttribute("data-theme", next);
          store.setItem("theme", next);
        });
      })();
    </script>
  </body>
</html>